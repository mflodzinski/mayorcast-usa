{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentages_with_suffix(row, suffix):\n",
    "    \"\"\"\n",
    "    Calculate percentage values for demographic groups dynamically based on a suffix.\n",
    "    Returns:\n",
    "        pandas.Series - The row with updated percentage values.\n",
    "    \"\"\"\n",
    "    columns = [f\"hispanic_{suffix}\", f\"white_{suffix}\", f\"black_{suffix}\", f\"asian_{suffix}\"]\n",
    "    total = sum(row[col] for col in columns if col in row)\n",
    "    \n",
    "    if total > 0:\n",
    "        for col in columns:\n",
    "            if col in row:\n",
    "                row[col] = (row[col] / total)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess 2000 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'data/race_2000.csv'\n",
    "df_race_2000 = pd.read_csv(csv_file_path)[['Geography', 'Population Groups', 'Number!!Total population']]\n",
    "\n",
    "def process_group(fips, group):\n",
    "    row = {\"fips\": fips}\n",
    "    population_groups = group.set_index('Population Groups')['Number!!Total population']\n",
    "    \n",
    "    # Hispanic population logic\n",
    "    if 'Hispanic or Latino (of any race) (200-299)' in population_groups:\n",
    "        row[\"hispanic_2000\"] = population_groups['Hispanic or Latino (of any race) (200-299)']\n",
    "    else:\n",
    "        row[\"hispanic_2000\"] = (\n",
    "            population_groups.get('White alone', 0) - population_groups.get('White alone, not Hispanic or Latino', 0)\n",
    "            if 'White alone' in population_groups and 'White alone, not Hispanic or Latino' in population_groups\n",
    "            else 0\n",
    "        )\n",
    "    \n",
    "    # Assign other population groups\n",
    "    row[\"white_2000\"] = population_groups.get('White alone, not Hispanic or Latino', \n",
    "                     population_groups.get('White alone', 0))\n",
    "    row[\"black_2000\"] = population_groups.get('Black or African American alone', 0)\n",
    "    row[\"asian_2000\"] = population_groups.get('Asian alone (400-499)', 0)\n",
    "    row[\"total_2000\"] = population_groups.get('Total population', 0)\n",
    "    return row\n",
    "\n",
    "df_race_2000 = pd.DataFrame(\n",
    "    process_group(fips, group)\n",
    "    for fips, group in df_race_2000.groupby('Geography')\n",
    ")\n",
    "\n",
    "df_race_2000['fips'] = df_race_2000['fips'].str.replace('1600000US', '')\n",
    "df_race_2000.rename(columns={'Geography': 'fips'}, inplace=True)\n",
    "df_race_2000 = df_race_2000.apply(calculate_percentages_with_suffix, axis=1, suffix=\"2000\")\n",
    "\n",
    "# Change wrong values\n",
    "df_race_2000.loc[df_race_2000['fips'] == \"1319007\", 'fips'] = \"1319000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>hispanic_2000</th>\n",
       "      <th>white_2000</th>\n",
       "      <th>black_2000</th>\n",
       "      <th>asian_2000</th>\n",
       "      <th>total_2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0100124</td>\n",
       "      <td>0.021922</td>\n",
       "      <td>0.586847</td>\n",
       "      <td>0.391231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0100460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792537</td>\n",
       "      <td>0.207463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0100484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0100676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0100820</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.872885</td>\n",
       "      <td>0.105914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fips  hispanic_2000  white_2000  black_2000  asian_2000  total_2000\n",
       "0  0100124       0.021922    0.586847    0.391231         0.0        3000\n",
       "1  0100460       0.000000    0.792537    0.207463         0.0        4774\n",
       "2  0100484       0.000000    1.000000    0.000000         0.0         714\n",
       "3  0100676       0.000000    0.000000    1.000000         0.0         543\n",
       "4  0100820       0.021200    0.872885    0.105914         0.0       23210"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_race_2000.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess 2010 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'data/race_2010.csv'\n",
    "df_2010 = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Remove unwanted artefacts\n",
    "df_2010['Total'] = df_2010['Total'].str.replace(r'\\(.*?\\)', '', regex=True)\n",
    "\n",
    "columns_to_extract = {\n",
    "    \"Geography\": \"fips\",\n",
    "    \"Total\": \"total_2010\",\n",
    "    \"Total!!Hispanic or Latino\": \"hispanic_2010\",\n",
    "    \"Total!!Not Hispanic or Latino!!Population of one race!!White alone\": \"white_2010\",\n",
    "    \"Total!!Not Hispanic or Latino!!Population of one race!!Black or African American alone\": \"black_2010\",\n",
    "    \"Total!!Not Hispanic or Latino!!Population of one race!!Asian alone\": \"asian_2010\",\n",
    "}\n",
    "\n",
    "df_race_2010 = df_2010[list(columns_to_extract.keys())].rename(columns=columns_to_extract)\n",
    "df_race_2010['fips'] = df_race_2010['fips'].str.replace('1600000US', '')\n",
    "df_race_2010 = df_race_2010.apply(calculate_percentages_with_suffix, axis=1, suffix=\"2010\")\n",
    "\n",
    "# Change wrong values\n",
    "df_race_2010.loc[df_race_2010['fips'] == \"2127982\", 'fips'] = \"2148000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>total_2010</th>\n",
       "      <th>hispanic_2010</th>\n",
       "      <th>white_2010</th>\n",
       "      <th>black_2010</th>\n",
       "      <th>asian_2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0100100</td>\n",
       "      <td>192</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>0.678947</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0100124</td>\n",
       "      <td>2688</td>\n",
       "      <td>0.030873</td>\n",
       "      <td>0.543298</td>\n",
       "      <td>0.417922</td>\n",
       "      <td>0.007907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0100460</td>\n",
       "      <td>4522</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>0.520726</td>\n",
       "      <td>0.453731</td>\n",
       "      <td>0.002689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0100484</td>\n",
       "      <td>758</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.993386</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.001323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0100676</td>\n",
       "      <td>356</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.129577</td>\n",
       "      <td>0.867606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fips total_2010  hispanic_2010  white_2010  black_2010  asian_2010\n",
       "0  0100100        192       0.015789    0.678947    0.305263    0.000000\n",
       "1  0100124       2688       0.030873    0.543298    0.417922    0.007907\n",
       "2  0100460       4522       0.022855    0.520726    0.453731    0.002689\n",
       "3  0100484        758       0.003968    0.993386    0.001323    0.001323\n",
       "4  0100676        356       0.002817    0.129577    0.867606    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_race_2010.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess 2020 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'data/race_2020.csv'\n",
    "df_2020 = pd.read_csv(csv_file_path)\n",
    "\n",
    "columns_to_extract = {\n",
    "    \"Geography\": \"fips\",\n",
    "    \" !!Total:\": \"total_2020\",\n",
    "    \" !!Total:!!Hispanic or Latino\": \"hispanic_2020\",\n",
    "    \" !!Total:!!Not Hispanic or Latino:!!Population of one race:!!White alone\": \"white_2020\",\n",
    "    \" !!Total:!!Not Hispanic or Latino:!!Population of one race:!!Black or African American alone\": \"black_2020\",\n",
    "    \" !!Total:!!Not Hispanic or Latino:!!Population of one race:!!Asian alone\": \"asian_2020\",\n",
    "}\n",
    "\n",
    "df_race_2020 = df_2020[list(columns_to_extract.keys())].rename(columns=columns_to_extract)\n",
    "df_race_2020['fips'] = df_race_2020['fips'].str.replace('1600000US', '')\n",
    "df_race_2020 = df_race_2020.apply(calculate_percentages_with_suffix, axis=1, suffix=\"2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>total_2020</th>\n",
       "      <th>hispanic_2020</th>\n",
       "      <th>white_2020</th>\n",
       "      <th>black_2020</th>\n",
       "      <th>asian_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0100100</td>\n",
       "      <td>133</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.255639</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0100124</td>\n",
       "      <td>2358</td>\n",
       "      <td>0.029476</td>\n",
       "      <td>0.509019</td>\n",
       "      <td>0.454905</td>\n",
       "      <td>0.006599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0100460</td>\n",
       "      <td>4366</td>\n",
       "      <td>0.043169</td>\n",
       "      <td>0.408918</td>\n",
       "      <td>0.545541</td>\n",
       "      <td>0.002372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0100484</td>\n",
       "      <td>659</td>\n",
       "      <td>0.012638</td>\n",
       "      <td>0.984202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0100676</td>\n",
       "      <td>225</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.085973</td>\n",
       "      <td>0.900452</td>\n",
       "      <td>0.009050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fips  total_2020  hispanic_2020  white_2020  black_2020  asian_2020\n",
       "0  0100100         133       0.030075    0.714286    0.255639    0.000000\n",
       "1  0100124        2358       0.029476    0.509019    0.454905    0.006599\n",
       "2  0100460        4366       0.043169    0.408918    0.545541    0.002372\n",
       "3  0100484         659       0.012638    0.984202    0.000000    0.003160\n",
       "4  0100676         225       0.004525    0.085973    0.900452    0.009050"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_race_2020.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def adjust_and_normalize_columns(df, columns, threshold=0.00001):\n",
    "    \"\"\"\n",
    "    Combines setting small values to zero, ensuring values are non-negative, \n",
    "    and normalizing the specified columns to sum to 1.\n",
    "    Returns:\n",
    "        pd.DataFrame: The modified DataFrame with adjusted and normalized columns.\n",
    "    \"\"\"\n",
    "    if not all(column in df.columns for column in columns):\n",
    "        raise ValueError(\"Some specified columns are not present in the DataFrame.\")\n",
    "\n",
    "    for column in columns:\n",
    "        df[column] = df[column].apply(lambda x: max(0, x))\n",
    "        df[column] = df[column].apply(lambda x: 0 if x < threshold else x)\n",
    "\n",
    "    # Normalize rows where the sum is greater than zero\n",
    "    column_sums = df[columns].sum(axis=1)\n",
    "    df[columns] = df[columns].div(column_sums.where(column_sums > 0, 1), axis=0)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_patterns = {\n",
    "    'df_race_2000': ['hispanic_2000', 'white_2000', 'black_2000', 'asian_2000'],\n",
    "    'df_race_2010': ['hispanic_2010', 'white_2010', 'black_2010', 'asian_2010'],\n",
    "    'df_race_2020': ['hispanic_2020', 'white_2020', 'black_2020', 'asian_2020']\n",
    "}\n",
    "\n",
    "# df_race_2000, df_race_2010, df_race_2020 should be defined\n",
    "for df_name, columns in column_patterns.items():\n",
    "    df = globals()[df_name]\n",
    "    globals()[df_name] = adjust_and_normalize_columns(df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge race datasets for easy lookup\n",
    "columns_to_estimate = ['hispanic', 'white', 'black', 'asian']\n",
    "\n",
    "race_data = df_race_2000[['fips', 'total_2000'] + [f'{col}_2000' for col in columns_to_estimate]].merge(\n",
    "    df_race_2010[['fips', 'total_2010'] + [f'{col}_2010' for col in columns_to_estimate]], on='fips'\n",
    ").merge(\n",
    "    df_race_2020[['fips', 'total_2020'] + [f'{col}_2020' for col in columns_to_estimate]], on='fips'\n",
    ")\n",
    "\n",
    "# Convert the 'fips' column to integers\n",
    "race_data['fips'] = race_data['fips'].astype(int)\n",
    "race_data = race_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_values_for_dataframe(df, race_data, columns):\n",
    "    \"\"\"\n",
    "    Estimate values for each row in a DataFrame based on given year and fips.\n",
    "    Returns:\n",
    "        pd.DataFrame: Original DataFrame with estimated values merged.\n",
    "    \"\"\"\n",
    "\n",
    "    def predict_linear_for_year(y_observed, x_observed, target_year):\n",
    "        \"\"\"\n",
    "        Predict the value for a given year using linear fitting.\n",
    "        \"\"\"\n",
    "        def linear_model(x, a, b):\n",
    "            return a * x + b\n",
    "\n",
    "        params, _ = curve_fit(linear_model, x_observed, y_observed)\n",
    "        predicted_value = linear_model(target_year, *params)\n",
    "        return predicted_value\n",
    "\n",
    "    observed_years = np.array([2000, 2010, 2020])\n",
    "    estimated_values = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        year = row['year']\n",
    "        fips = row['fips']\n",
    "        race_row = race_data[race_data['fips'] == fips]\n",
    "\n",
    "        if race_row.empty:\n",
    "            estimated_values.append({col: np.nan for col in columns})\n",
    "            continue\n",
    "\n",
    "        race_row = race_row.iloc[0]\n",
    "\n",
    "        estimates = {}\n",
    "        for col in columns:\n",
    "            y_observed = np.array([\n",
    "                race_row[f'{col}_2000'],\n",
    "                race_row[f'{col}_2010'],\n",
    "                race_row[f'{col}_2020']\n",
    "            ])\n",
    "            estimates[col] = predict_linear_for_year(y_observed, observed_years, year)\n",
    "\n",
    "        estimated_values.append(estimates)\n",
    "\n",
    "    estimated_df = pd.DataFrame(estimated_values)\n",
    "    result_df = pd.concat([df.reset_index(drop=True), estimated_df], axis=1)\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_estimate = ['total', 'hispanic', 'white', 'black', 'asian']\n",
    "\n",
    "df_mayor = pd.read_csv('data/data_mayoral.csv')\n",
    "df_mayor = estimate_values_for_dataframe(df_mayor, race_data, columns_to_estimate)\n",
    "df_mayor['total'] = df_mayor['total'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_normalize = ['hispanic', 'white', 'black', 'asian']\n",
    "df_mayor = adjust_and_normalize_columns(df_mayor, columns_to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_abb</th>\n",
       "      <th>geo_name</th>\n",
       "      <th>year</th>\n",
       "      <th>contest</th>\n",
       "      <th>fips</th>\n",
       "      <th>full_name_rep</th>\n",
       "      <th>vote_share_rep</th>\n",
       "      <th>incumbent_rep</th>\n",
       "      <th>contributor.cfscore_rep</th>\n",
       "      <th>prob_democrat_rep</th>\n",
       "      <th>...</th>\n",
       "      <th>gender_est_dem</th>\n",
       "      <th>race_est_dem</th>\n",
       "      <th>pid_est_dem</th>\n",
       "      <th>percent_women</th>\n",
       "      <th>pres_pctD</th>\n",
       "      <th>total</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>asian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE</td>\n",
       "      <td>wilmington</td>\n",
       "      <td>1992</td>\n",
       "      <td>151000_2019_10_montgomery_AL_Mayor_mayor_1</td>\n",
       "      <td>1077580</td>\n",
       "      <td>beatrice patton carroll</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.011667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>non_white</td>\n",
       "      <td>D</td>\n",
       "      <td>0.525989</td>\n",
       "      <td>0.891903</td>\n",
       "      <td>73060</td>\n",
       "      <td>0.086214</td>\n",
       "      <td>0.337033</td>\n",
       "      <td>0.570731</td>\n",
       "      <td>0.006021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE</td>\n",
       "      <td>wilmington</td>\n",
       "      <td>1996</td>\n",
       "      <td>2148000_1998_11_louisville_KY_Mayor_mayor_1</td>\n",
       "      <td>1077580</td>\n",
       "      <td>bradley zuber</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>non_white</td>\n",
       "      <td>D</td>\n",
       "      <td>0.525989</td>\n",
       "      <td>0.890173</td>\n",
       "      <td>72707</td>\n",
       "      <td>0.094095</td>\n",
       "      <td>0.327885</td>\n",
       "      <td>0.571025</td>\n",
       "      <td>0.006995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE</td>\n",
       "      <td>wilmington</td>\n",
       "      <td>2004</td>\n",
       "      <td>2205000_2016_12_baton rouge_LA_Mayor_mayor_1</td>\n",
       "      <td>1077580</td>\n",
       "      <td>robert bovell</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>D</td>\n",
       "      <td>0.525989</td>\n",
       "      <td>0.886721</td>\n",
       "      <td>72000</td>\n",
       "      <td>0.109856</td>\n",
       "      <td>0.309588</td>\n",
       "      <td>0.571614</td>\n",
       "      <td>0.008942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE</td>\n",
       "      <td>wilmington</td>\n",
       "      <td>2016</td>\n",
       "      <td>1263000_2021_11_st. petersburg_FL_Mayor_mayor_1</td>\n",
       "      <td>1077580</td>\n",
       "      <td>robert martin</td>\n",
       "      <td>0.118280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>D</td>\n",
       "      <td>0.525989</td>\n",
       "      <td>0.878289</td>\n",
       "      <td>70941</td>\n",
       "      <td>0.133499</td>\n",
       "      <td>0.282142</td>\n",
       "      <td>0.572496</td>\n",
       "      <td>0.011863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DC</td>\n",
       "      <td>washington</td>\n",
       "      <td>1990</td>\n",
       "      <td>2404000_2020_11_baltimore_MD_Mayor_mayor_1</td>\n",
       "      <td>1150000</td>\n",
       "      <td>maurice turner</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>non_white</td>\n",
       "      <td>D</td>\n",
       "      <td>0.525549</td>\n",
       "      <td>0.914489</td>\n",
       "      <td>503623</td>\n",
       "      <td>0.058937</td>\n",
       "      <td>0.229147</td>\n",
       "      <td>0.698828</td>\n",
       "      <td>0.013088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_abb    geo_name  year  \\\n",
       "0        DE  wilmington  1992   \n",
       "1        DE  wilmington  1996   \n",
       "2        DE  wilmington  2004   \n",
       "3        DE  wilmington  2016   \n",
       "4        DC  washington  1990   \n",
       "\n",
       "                                           contest     fips  \\\n",
       "0       151000_2019_10_montgomery_AL_Mayor_mayor_1  1077580   \n",
       "1      2148000_1998_11_louisville_KY_Mayor_mayor_1  1077580   \n",
       "2     2205000_2016_12_baton rouge_LA_Mayor_mayor_1  1077580   \n",
       "3  1263000_2021_11_st. petersburg_FL_Mayor_mayor_1  1077580   \n",
       "4       2404000_2020_11_baltimore_MD_Mayor_mayor_1  1150000   \n",
       "\n",
       "             full_name_rep  vote_share_rep  incumbent_rep  \\\n",
       "0  beatrice patton carroll        0.090000            0.0   \n",
       "1            bradley zuber        0.390000            0.0   \n",
       "2            robert bovell        0.270000            0.0   \n",
       "3            robert martin        0.118280            0.0   \n",
       "4           maurice turner        0.113402            0.0   \n",
       "\n",
       "   contributor.cfscore_rep  prob_democrat_rep  ... gender_est_dem  \\\n",
       "0                 1.011667                0.0  ...              M   \n",
       "1                 0.927143                0.0  ...              M   \n",
       "2                 0.776190                0.0  ...              M   \n",
       "3                 1.010000                0.0  ...              M   \n",
       "4                 0.843333                0.0  ...              F   \n",
       "\n",
       "  race_est_dem pid_est_dem percent_women  pres_pctD   total  hispanic  \\\n",
       "0    non_white           D      0.525989   0.891903   73060  0.086214   \n",
       "1    non_white           D      0.525989   0.890173   72707  0.094095   \n",
       "2        white           D      0.525989   0.886721   72000  0.109856   \n",
       "3        white           D      0.525989   0.878289   70941  0.133499   \n",
       "4    non_white           D      0.525549   0.914489  503623  0.058937   \n",
       "\n",
       "      white     black     asian  \n",
       "0  0.337033  0.570731  0.006021  \n",
       "1  0.327885  0.571025  0.006995  \n",
       "2  0.309588  0.571614  0.008942  \n",
       "3  0.282142  0.572496  0.011863  \n",
       "4  0.229147  0.698828  0.013088  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mayor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mayor.to_csv('data/data_mayoral.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
